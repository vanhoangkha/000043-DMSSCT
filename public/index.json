[
{
	"uri": "/",
	"title": "AWS Database Migration",
	"tags": [],
	"description": "",
	"content": "AWS Database Migration In this workshop, we will explore how you can migrate your data to and from most widely used commercial and open-source databases using the AWS Database Migration Service (DMS) and AWS Schema Conversion Tool (AWS SCT).\nContents In this exercise you perform the following tasks:\n Pre-requisites Oracle to Amazon Aurora (PostgreSQL) Clean Up  "
},
{
	"uri": "/2-oracle-aurora/1-conversion/1-connect-ec2/",
	"title": "Connect to EC2",
	"tags": [],
	"description": "",
	"content": "Contents\n Connect to the EC2 instance   Connect to the EC2 instance  Go to the AWS EC2 console and click on Instances in the left column.  Select the instance with the name \u0026lt;StackName\u0026gt;-EC2Instance and then click the Actions button. Click on Connect.  Go to the RDP client section, and click on Get Password.  Click on Browse and upload the Key Pair file that you downloaded earlier. Click on Decrypt Password.  Copy the generated password to your notepad. You will use this password to connect to login to the EC2 instance.  Click on Download Remote Desktop File to download the RDP file to access this EC2 instance. Connect to the EC2 instance using a RDP client.  "
},
{
	"uri": "/2-oracle-aurora/2-migration/1-connect-source-db/",
	"title": "Connect to Source DB",
	"tags": [],
	"description": "",
	"content": "Contents\n Connect to Source Oracle Database   Connect to Source Oracle Database If you disconnected from the Source EC2 instance, follow the instruction in Connect to the EC2 Instance section from the previous part to RDP to the instance.\n\r Once connected, open Oracle SQL Developer from the Taskbar.  Click on the plus sign from the left-hand menu to create a New Database Connection using the following values, then click Connect.     Parameter Value     Connection Name Source Oracle   Username dbmaster   Password dbmaster123   **Save Password ** Check   Hostname \u0026lt; SourceOracleEndpoint \u0026gt;   Port 1521   SID ORACLEDB    After the you see the test status as Successful, click Connect.  "
},
{
	"uri": "/3-cleanup/1-dms-task/",
	"title": "Database Migration Task",
	"tags": [],
	"description": "",
	"content": "Contents\n Delete the Database Migration Task   Delete the Database Migration Task  Access Database Migration Service (AWS DMS) console. On the left-hand menu click on Database migration tasks, and select the migration tasks that you created one at a time.  Click on the Actions button on the right-hand side, and then select Stop.  Confirm that you want to stop the migration task.  After the status of the migration tasks changes to Stopped, click on the Actions button again, and then select Delete.  Confirm that you want to delete the migration task.  Continue to Delete the DMS Endpoints\u0026hellip;\n"
},
{
	"uri": "/1-prerequisites/1-console/",
	"title": "Login to Console",
	"tags": [],
	"description": "",
	"content": "Contents:\n Login to Console   Login to Console  Login to AWS Management Console using your credentials. Click on the drop-down menu on the top right corner of the screen, and select one of the 12 supported regions for this tutorial:     Region Name Region     US East (N. Virginia) us-east-1   US East (Ohio) us-east-2   US West (Oregon) us-west-2   EU (Frankfurt) eu-central-1   EU (Ireland) eu-west-1   EU (London) eu-west-2   EU (Paris) eu-west-3   Asia Pacific (Mumbai) ap-south-1   Asia Pacific (Tokyo) ap-northeast-1   Asia Pacific (Seoul) ap-northeast-2   Asia Pacific (Singapore) ap-southeast-1   Asia Pacific (Sydney) ap-southeast-2    "
},
{
	"uri": "/1-prerequisites/",
	"title": "Pre-requisites",
	"tags": [],
	"description": "",
	"content": "Pre-requisites\nThis section describes the steps to provision the AWS resources that are required for this database migration walkthrough.\nWe use AWS CloudFormation to simplify the provisioning of the infrastructure, so we can concentrate on tasks related to data migration.\nThe CFN Template creates a basic network topology that includes Amazon Virtual Privsate Cloud (Amazon VPC) with 3 public subnets to deploy the AWS Database Migration Service (AWS DMS) replication instance, as well as Amazon Relational Database Service (Amazon RDS) instance for the target database. Additionally, it provisions an Amazon Elastic Compute Cloud (EC2) instance to host the tools that we use in this migration, including the AWS Schema Conversion Tool (AWS SCT). Likewise, in the Microsoft SQL Server migration workshop, we use this EC2 instance to simulate our source database.\nWe use Remote Desktop Protocol (RDP) to connect to the Amazon EC2 Instance. Please ensure you have a RDP client such as Microsoft Remote Desktop installed on your workstation.\n\rThe resources provisioned as part of this workshop will incur charges. Remember to use the Environment Cleanup guide after you have completed the workshop to stop incurring additional costs.\n\rContents  Login to AWS Management Console Create a new EC2 Keypair Configure the Environment  "
},
{
	"uri": "/2-oracle-aurora/1-conversion/",
	"title": "Schema Conversion",
	"tags": [],
	"description": "",
	"content": "Schema Conversion\nThis section demonstrates how to use the AWS Schema Conversion Tool for converting an Oracle database schema to an Amazon Aurora (PostgreSQL) database. Additionally, you will observe how AWS SCT helps you spot the differences between the two dialects; and, provides you with tips about how you can modify procedural code when needed to successfully migrate all database objects.\nIn this exercise, you perform the following tasks:\nContents:  Connect to the EC2 Instance Install the AWS Schema Conversion Tool (AWS SCT) Create a Database Migration Project Convert the Schema  "
},
{
	"uri": "/2-oracle-aurora/2-migration/2-config-source-db/",
	"title": "Configure the Source DB",
	"tags": [],
	"description": "",
	"content": "Contents\n Configure the Source Database   Configure the Source Database To use Oracle as a source for AWS Database Migration Service (AWS DMS), you must first provide a user account (DMS user) with read and write privileges on the Oracle database.\nYou also need to ensure that ARCHIVELOG MODE is on to provide information to LogMiner. AWS DMS uses LogMiner to read information from the archive logs so that AWS DMS can capture changes.\nFor AWS DMS to read this information, make sure the archive logs are retained on the database server as long as AWS DMS requires them. Retaining archive logs for 24 hours is usually sufficient.\nTo capture change data, AWS DMS requires database-level supplemental logging to be enabled on your source database. Doing this ensures that the LogMiner has the minimal information to support various table structures such as clustered and index-organized tables.\nSimilarly, you need to enable table-level supplemental logging for each table that you want to migrate.\n Click on the SQL Worksheet icon within Oracle SQL Developer, then connect to the Source Oracle database.  Next, execute the below statements to grant the following privileges to the AWS DMS user to access the source Oracle endpoint:  GRANT SELECT ANY TABLE to DMS_USER;\rGRANT SELECT on ALL_VIEWS to DMS_USER;\rGRANT SELECT ANY TRANSACTION to DMS_USER;\rGRANT SELECT on DBA_TABLESPACES to DMS_USER;\rGRANT SELECT on ALL_TAB_PARTITIONS to DMS_USER;\rGRANT SELECT on ALL_INDEXES to DMS_USER;\rGRANT SELECT on ALL_OBJECTS to DMS_USER;\rGRANT SELECT on ALL_TABLES to DMS_USER;\rGRANT SELECT on ALL_USERS to DMS_USER;\rGRANT SELECT on ALL_CATALOG to DMS_USER;\rGRANT SELECT on ALL_CONSTRAINTS to DMS_USER;\rGRANT SELECT on ALL_CONS_COLUMNS to DMS_USER;\rGRANT SELECT on ALL_TAB_COLS to DMS_USER;\rGRANT SELECT on ALL_IND_COLUMNS to DMS_USER;\rGRANT SELECT on ALL_LOG_GROUPS to DMS_USER;\rGRANT LOGMINING TO DMS_USER;\rIn addition, run the following:  exec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$ARCHIVED_LOG\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$LOG\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$LOGFILE\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$DATABASE\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$THREAD\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$PARAMETER\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$NLS_PARAMETERS\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$TIMEZONE_NAMES\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$TRANSACTION\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;DBA_REGISTRY\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;OBJ$\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;ALL_ENCRYPTED_COLUMNS\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$LOGMNR_LOGS\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;V_$LOGMNR_CONTENTS\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;SELECT\u0026#39;);\rexec rdsadmin.rdsadmin_util.grant_sys_object(\u0026#39;DBMS_LOGMNR\u0026#39;,\u0026#39;DMS_USER\u0026#39;,\u0026#39;EXECUTE\u0026#39;);\rRun the following query to retain archived redo logs of the source Oracle database instance for 24 hours:  exec rdsadmin.rdsadmin_util.set_configuration(\u0026#39;archivelog retention hours\u0026#39;,24);\rRun the following query to enable database-level supplemental logging:  exec rdsadmin.rdsadmin_util.alter_supplemental_logging(\u0026#39;ADD\u0026#39;);\rRun the following query to enable PRIMARY KEY logging for tables that have primary keys:  exec rdsadmin.rdsadmin_util.alter_supplemental_logging(\u0026#39;ADD\u0026#39;,\u0026#39;PRIMARY KEY\u0026#39;);\rRun the following queries to add supplemental logging for tables that don’t have primary keys, use the following command to add supplemental logging:  alter table dms_sample.nfl_stadium_data add supplemental log data (ALL) columns;\ralter table dms_sample.mlb_data add supplemental log data (ALL) columns;\ralter table dms_sample.nfl_data add supplemental log data (ALL) columns;\r"
},
{
	"uri": "/1-prerequisites/2-create-kp/",
	"title": "Create EC2 key pair",
	"tags": [],
	"description": "",
	"content": "Contents:\n Create EC2 key pair   Create EC2 key pair In this step, you will generate an EC2 key pair that you will use to connect to the EC2 instance.\n Click here to navigate to the Key Pair section in the EC2 console. Ensure you are in the same region as you chose in the previous step. Then, click on the Create Key Pair button  Name the key pair DMSKeyPair, and then click Create. At this point, your browser will download a file named DMSKeyPair.pem. Save this file. You will need it to complete the tutorial.  Remember the location that you save key pair .pem on your computer. You will use this file later.\n\r"
},
{
	"uri": "/2-oracle-aurora/2-migration/",
	"title": "Data Migration",
	"tags": [],
	"description": "",
	"content": "Data Migration\nPlease note that you need to complete the steps described in Schema Conversion section as a pre-requisite for this part.\n\rThis section will demonstrate how you can use the AWS Database Migration Service to migrate data from an Oracle database to an Amazon Aurora (PostgreSQL) instance. Additionally, you will use AWS DMS to continually replicate database changes from the source database to the target database. We do this in two steps:\nFirst, you perform a full load migration of source oracle database to target Aurora PostgreSQL database using AWS DMS.\nNext, you capture data changes (CDC) from the Oracle database, and replicate them automatically to Aurora PostgreSQL instance using AWS DMS.\nAWS DMS doesn’t migrate your secondary indexes, sequences, default values, stored procedures, triggers, synonyms, views, and other schema objects that aren’t specifically related to data migration. To migrate these objects to your Aurora (PostgreSQL) target, we used the AWS Schema Conversion Tool in the previous section.\nIn this exercise, you perform the following tasks:\nContents:  Connect To The Source Oracle Database Configure the Source Database Configure the Target Database Create a DMS Replication Instance Create DMS Source and Target Endpoints Create a DMS Migration Task Inspect the Content of Target Database Replicate Data Changes  "
},
{
	"uri": "/3-cleanup/2-dms-endpoints/",
	"title": "DMS Endpoints",
	"tags": [],
	"description": "",
	"content": "Contents\n Delete the DMS Endpoints   Delete the DMS Endpoints  Still in the Database Migration Service console, click on Endpoints in the left-hand menu. Select the endpoints that you created as a part of the workshop. Then, click on the Actions button on the right-hand side, and choose Delete.  Confirm that you want to delete the endpoints.  Continue to Delete the DMS Replication instance\u0026hellip;\n"
},
{
	"uri": "/2-oracle-aurora/",
	"title": "Oracle to Amazon Aurora (PostgreSQL)",
	"tags": [],
	"description": "",
	"content": "Oracle to Amazon Aurora (PostgreSQL)\nNow that you have completed setting up the workshop enviornment, you are ready to migrate a sample data base.\nThis step-by-step guide demonstrates how you can use AWS Database Migration Service (DMS) and AWS Schema Conversion Tool (AWS SCT) to migrate data from an Oracle database to Amazon Aurora (PostgreSQL). Additionally, you will use AWS DMS to continually replicate database changes from the source database to the target database.\nThe environment for this lab consists of:\n An Amazon EC2 instance used to run the AWS Schema Conversion Tool (SCT) as well as other applications needed to complete the lab. An Amazon RDS instance used to host the source Oracle database. An Amazon RDS Aurora (PostgreSQL) instance used as the target database.  Before proceeding further, make sure you have completed the instructions in the Pre-requisites section that preceeded this chapter.\n\rContents  Schema Conversion Data Migration Summary  "
},
{
	"uri": "/2-oracle-aurora/1-conversion/2-aws-sct/",
	"title": "Schema Conversion Tools",
	"tags": [],
	"description": "",
	"content": "Contents\n Install the AWS Schema Conversion Tool (AWS SCT)   Install the AWS Schema Conversion Tool (AWS SCT) Now that you are connected to the EC2 instance, you are going to install the AWS Schema Conversion tool on the server. Downloading the file and installing it will give you the latest version of the AWS Schema Conversion Tool.\n On the EC2 server, open the DMS Workshop folder that is on the Desktop. Then, double-click on AWS Schema Conversion Tool Download to get the latest version of the software.  When the download is complete, unzip the content and install the AWS Schema Conversion Tool.  When the installer is complete the installation dialog will disappear. There is no other notification.\n\rOnce the installation is complete, go to the Start Menu and launch the AWS Schema Conversion Tool.  Accept the terms and Conditions.  "
},
{
	"uri": "/3-cleanup/",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": "Environment Cleanup\nAfter you have completed the database migration workshop, you need to remove the AWS resources that you created in your account to stop incurring costs. This section walks you through the steps to delete these resources…\nContents  Delete the Database Migration Task Delete the DMS Endpoints Delete the DMS Replication Instance Delete the CloudFormation Stack  "
},
{
	"uri": "/1-prerequisites/3-config-env/",
	"title": "Config the Environment",
	"tags": [],
	"description": "",
	"content": "Contents:\n Config the Environment   Config the Environment In this step, you will use a CloudFormation (CFN) template to deploy the infrastructure for this database migration. AWS CloudFormation simplifies provisioning the infrastructure, so we can concentrate on tasks related to data migration.\n Open the AWS CloudFormation console, and click on Create Stack in the left-hand corner.  Select Template is ready, and choose Upload a template file as the source template. Then, click on Choose file and upload the DMSWorkshop.yaml. Click Next.  \r\rTemplate\r\r\rDMSWorkshop.yaml\r\r(23 ko)\r\r\r\rPopulate the form as with the values specified below, and then click Next.     Input Parameter Values     Stack Name A unique identifier without spaces.   MigrationType Database that you want to migrate (Oracle or SQL Server).   KeyName The KeyPair (DMSKeypair) that you created in the previous step.   EC2ServerInstanceType An Amazon EC2 Instance type from the drop-down menu. Recommend using the default value.   RDSInstanceType An Amazon RDS Instance type from the drop-down menu. Recommend using the default value.   VpcCIDR The VPC CIDR range in the form x.x.x.x/16. Defaults to 10.20.0.0/16   Subnet1CIDR The Subnet CIDR range for subnet 1 in the form x.x.x.x/24. Defaults to 10.20.1.0/24   Subnet2CIDR The Subnet CIDR range for subnet 2 in the form x.x.x.x/24. Defaults to 10.20.2.0/24   Subnet3CIDR The Subnet CIDR range for subnet 3 in the form x.x.x.x/24. Defaults to 10.20.3.0/24    The resources that are created here will be prefixed with whatever value you specify in the Stack Name. Please specify a value that is unique to your account.\n\rOn the Stack Options page, accept all of the defaults and click Next. On the Review page, click Create stack.  At this point, you will be directed back to the CloudFormation console and will see a status of CREATE_IN_PROGRESS. Please wait here until the status changes to COMPLETE.  Once CloudFormation status changes to CREATE_COMPLETE, go to the Outputs section. Make a note of the Output values from the CloudFormation environment that you launched as you will need them for the remainder of the tutorial:   Microsoft SQL Server to Amazon Aurora (MySQL) migration:   Oracle to Amazon Aurora (PostgreSQL) migration:     "
},
{
	"uri": "/2-oracle-aurora/2-migration/3-config-target-db/",
	"title": "Configure the Target DB",
	"tags": [],
	"description": "",
	"content": "Contents\n Configure the Target Database   Configure the Target Database During the full load process, AWS DMS does not load tables in any particular order, so it might load the child table data before parent table data. As a result, foreign key constraints might be violated if they are enabled. Also, if triggers are present on the target database, they might change data loaded by AWS DMS in unexpected ways. To overcome this, we drop the constraints on the target database.\n\r Open pgAdmin 4 from the Taskbar on the EC2 server.  You may be prompted to set a Master Password. Enter dbmaster123, then click, OK.  Click on the Add New Server icon, and enter the following values. Then, press Save.     Parameter Value     General -\u0026gt; Name Target Aurora RDS (PostgreSQL)   Connection -\u0026gt; Host Name/Address \u0026lt; TargetAuroraPostgreSQLEndpoint \u0026gt;   Connection -\u0026gt; Port 5432   Connection -\u0026gt; Username dbmaster   Connection -\u0026gt; Password dbmaster123   Connection -\u0026gt; Save Password Check    Right-click on AuroraDB database from left-hand menu, and then select Query Tool.  In this step you are going to drop the foreign key constraint from the target database:  \r\rDrop Key Constraint File\r\r\rDropConstraintsPostgreSQL.sql\r\r(1 ko)\r\r\r\r Open DropConstraintsPostgreSQL.sql in your favorite text editor. Copy the content of the file to the Query Editor in pgAdmin 4. Execute the script.  "
},
{
	"uri": "/2-oracle-aurora/1-conversion/3-dms-project/",
	"title": "Database Migration Project",
	"tags": [],
	"description": "",
	"content": "Contents\n Create a Database Migration Project   Create a Database Migration Project Now that you have installed the AWS Schema Conversion Tool, the next step is to create a Database Migration Project using the tool.\n Within the Schema Conversion Tool, enter the following values into the form and then click Next.     Parameter Value     Project Name AWS Schema Conversion Tool Oracle to Aurora PostgreSQL   Location C:\\Users\\Administrator\\AWS Schema Conversion Tool\\Projects   Database Type Transactional Database (OLTP)   Source Database Engine Oracle / I want to switch engines and optimize for the cloud    Specify the source database configurations in the form, and click Test Connection. Once the connection is successfully tested, click Next.     Parameter Value     Type SID   Server Name \u0026lt; SourceOracleEndpoint \u0026gt;   Server Port 1521   Oracle SID ORACLEDB   User Name dbmaster   Password dbmaster123   Use SSL Unchecked   Store Password Checked   Oracle Driver Path C:\\Users\\Administrator\\Desktop\\DMS Workshop\\JDBC\\ojdbc8.jar    You may see a security warning prompt to use SSL. Click on \u0026ldquo;Accept the risk and continue\u0026rdquo; button.\n\rSelect the DMS_SAMPLE database, then click Next.  After hitting Next and loading metadata, you may get a warning message saying: Metadata loading was interrupted because of data fetching issues. You can ignore this message as it doesn’t affect us in this workshop.\n\rReview the Database Migration Assessment Report.  SCT will examine in detail all of the objects in the schema of source database. It will convert as much as possible automatically and provides detailed information about items it could not convert.\nGenerally, packages, procedures, and functions are more likely to have some issues to resolve because they contain the most custom or proprietary SQL code. AWS SCT specifies how much manual change is needed to convert each object type. It also provides hints about how to adapt these objects to the target schema successfully.\nAfter you are done reviewing the database migration assessment report, click Next. Specify the target database configurations in the form, and then click Test Connection. Once the connection is successfully tested, click Finish.     Parameter Value     Target Database Engine Amazon Aurora (PostgreSQL compatible)   Server Name \u0026lt; TargetAuroraPostgreSQLEndpoint \u0026gt;   Server Port 5432   Database Name AuroraDB   User Name dbmaster   Password dbmaster123   Use SSL Unchecked   Store Password Checked   Amazon Aurora Driver Path C:\\Users\\Administrator\\Desktop\\DMS Workshop\\JDBC\\postgresql-42.2.9.jar    You may see a warning message saying database version that you connected to is 11.7 which is less than the recommended PostgreSQL 12.0. You can ignore the warning. \r"
},
{
	"uri": "/3-cleanup/3-replication-instance/",
	"title": "DMS Replication instance",
	"tags": [],
	"description": "",
	"content": "Contents\n Delete the DMS Replication instance   Delete the DMS Replication instance  Still in the Database Migration Service console, click on Replication instances in the left-hand menu. Select the replication instance that you created as a part of the workshop. Then, click on the Actions button on the right-hand side, and choose Delete.  Confirm that you want to delete the replication instance.  Continue to Delete the CloudFormation Stack\u0026hellip;\n"
},
{
	"uri": "/2-oracle-aurora/3-summary/",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "Contents\n Summary   Summary In the first part of this tutorial we saw how easy it is to convert the database schema from an Oracle database into Amazon Aurora (PostgreSQL) using the AWS Schema Conversion Tool (AWS SCT). In the second part, we used the AWS Database Migration Service (AWS DMS) to migrate the data from our source to target database with no downtime. Similarly, we observed how DMS automatically replicates new transactions on the source to target database.\nYou can follow the same steps to migrate SQL Server and Oracle workloads to other RDS engines including PostgreSQL and MySQL.\nThe resources provisined as part of this workshop will incur charges. Follow the instructions in the Cleanup section to remove these resources.\n\r"
},
{
	"uri": "/3-cleanup/4-cf-stack/",
	"title": "CloudFormation Stack",
	"tags": [],
	"description": "",
	"content": "Contents\n Delete the CloudFormation Stack   Delete the CloudFormation Stack  Next, go to the CloudFormation console, and click select the CloudFormation Stack that you created during the workshop. Click on the Delete button from the top right corner. CloudFormation will automatically remove all resources that it launched earlier. This process can take up to 15 minutes.  Confirm that you want to delete the stack.  Check the CloudFormation console to ensure the stack that you selected is removed.  "
},
{
	"uri": "/2-oracle-aurora/1-conversion/4-convert/",
	"title": "Convert the Schema",
	"tags": [],
	"description": "",
	"content": "Contents\n Convert the Schema   Convert the Schema  Right-click on the DMS_SAMPLE schema from Oracle source and select Convert Schema to generate the data definition language (DDL) statements for the target database.  You can view the generated DDL in the project console, and edit it before applying it to the target database. You can also choose to save it as an .sql file for application later.\nYou may be prompted with a dialog box \u0026ldquo;Object may already exist in the target database, replace?\u0026quot; Select Yes and conversion will start.\n\rAWS SCT analyses the schema and creates a database migration assessment report for the conversion to PostgreSQL. Items with a red exclamation mark next to them cannot be directly translated from the source to the target. This includes Stored Procedures, and Packages.\nClick on the View button, and choose Assessment Report view.  Next, navigate to the Action Items tab in the report to see the items that the tool could not convert, and find out how much manual changes you need to make.  Check each of the issues listed and compare the contents under the source Oracle panel and the target Aurora PostgreSQL panel. Are the issues resolved? And how?\nAWS SCT analyses the source Oracle database and creates a database migration assessment report for the conversion to Autora PostgreSQL. Items with a red exclamation mark next to them cannot be automatically converted by the AWS SCT. This includes Stored Procedures, and Packages. You need to manually modify these objects to make them compatible with the target database. You can complete one of the following actions to fix the issue:\n1. Modify the objects on the source Oracle database so that AWS SCT can convert the objects to the target Aurora PostgreSQL database.\\\r2. Instead of modifying the source Oracle database object, modify scripts that AWS SCT generates before applying the scripts on the target Aurora PostgreSQL database.\rFor the sake of time, we skip modifying all the objects that AWS SCT has marked that it could not be automatically converted. Instead, as an example, we will manually modify the GENERATESEATS, and the GENERATE_TICKETS stored procedures from within SCT to make them compatible with the target database.\nIf you click on the GENERATESEATS, and the GENERATE_TICKETS stored procedures, you will see that SCT is unable to automatically convert code as APPEND Hint is not supported in PostgreSQL.\nClick on the GENERATESEATS procedure and remove /*+ APPEND */ from the INSERT statement.  Similarly, click on GENERATE_TICKETS procedure and remove /*+ APPEND */ from the INSERT statement. Right click on the dms_sample schema in the left-hand panel, and click Create report.  Notice that all both modified objects are now compatible with the target database dialect.  Click on the dms_sample schema in the left-hand panel, and click Convert Schema.  You may be prompted with a dialog box \u0026ldquo;Object may already exist in the target database, replace?\u0026quot;. Select Yes.  Right click on the dms_sample schema in the right-hand panel, and click Apply to database.  When prompted if you want to apply the schema to the database, click Yes.  At this point, the schema has been applied to the target database. Expand the dms_sample schema to see the tables.  You may see an exclamation mark on certain database objects such as indexes, and foreign key constraints. In the next section we will drop foreign key target database.\n\rYou have successfully converted the database schema and object from Oracle to the format compatible with Amazon Aurora (PostgreSQL).\nThis part demonstrated how easy it is to migrate the schema of an Oracle database into Amazon Aurora (PostgreSQL) using the AWS Schema Conversion Tool. Similarly, you learned how the Schema Conversion Tool highlights the differences between different database engine dialects, and provides you with tips on how you can successfully modify the code when needed to migrate procedure and other database objects.\nThe same steps can be followed to migrate SQL Server and Oracle workloads to other RDS engines including PostgreSQL and MySQL.\nThe next section describes the steps required to move the actual data using AWS DMS.\n"
},
{
	"uri": "/2-oracle-aurora/2-migration/4-dms-replication/",
	"title": "DMS Replication Instance",
	"tags": [],
	"description": "",
	"content": "Contents\n Create a DMS Replication Instance   Create a DMS Replication Instance The following illustration shows a high-level view of the migration process.\nAn AWS DMS replication instance performs the actual data migration between source and target. The replication instance also caches the transaction logs during the migration. The amount of CPU and memory capacity of a replication instance influences the overall time that is required for the migration.\n\r Navigate to the Database Migration Service (DMS) console. On the left-hand menu click on Replication Instances. This will launch the Replication instance screen. Click on the Create replication instance button on the top right side.  Enter the following information for the Replication Instance. Then, click on the Create button. | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Name | DMSReplication | | Description | Replication server for Database Migration | | Instance Class | dms.c5.xlarge | | Engine version | Leave the default value | | Allocated storage (GB) | 50 | | VPC | \u0026lt; VPC ID from Environment Setup Step \u0026gt; | | Multi-AZ | No | | Publicly accessible | No | | Advanced -\u0026gt; VPC Security Group(s) | default |  Creating replication instance will take several minutes. While waiting for the replication instance to be created, you can specify the source and target database endpoints in the next steps. However, test connectivity only after the replication instance has been created, because the replication instance is used in the connection.\n\r"
},
{
	"uri": "/4-video/",
	"title": "Video Guide",
	"tags": [],
	"description": "",
	"content": "Link for Video Guide: DMS/SCT Lab\n"
},
{
	"uri": "/2-oracle-aurora/2-migration/5-endpoints/",
	"title": "Source &amp; Target Endpoints",
	"tags": [],
	"description": "",
	"content": "Contents\n Create DMS Source and Target Endpoints   Create DMS Source and Target Endpoints Now that you have a replication instance, you need to create source and target endpoints for the sample database.\n  Click on the Endpoints link on the left, and then click on Create endpoint on the top right corner.   Enter the following information to create an endpoint for the source dms_sample database: | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Endpoint Type | Source endpoint | | Select RDS DB instance | Check | | RDS Instance | \u0026lt; StackName \u0026gt;-SourceOracleDB | | Endpoint Identifier | oracle-source | | Source Engine | oracle | | Access to endpoint database | Provide access information manually | | Server Name | \u0026lt; SourceOracleEndpoint \u0026gt; | | Port | 1521 | | SSL Mode | none | | User Name | dbmaster | | Password | dbmaster123 | | SID/Service Name | ORACLEDB | | Test endpoint connection -\u0026gt; VPC | \u0026lt; VPC ID from Environment Setup Step \u0026gt; | | Replication Instance | oracle-replication |\n  Once the information has been entered, click Run Test. When the status turns to successful, click Create endpoint. Follow the same steps to create another endpoint for the Target Aurora RDS Database using the following values: | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Endpoint Type | Target endpoint | | Select RDS DB instance | \u0026lt; StackName \u0026gt;-AuroraPostgreSQLInstance | | Endpoint Identifier | aurora-target | | Target Engine | aurora-postgresql | | Access to endpoint database | Provide access information manually | | Server Name | \u0026lt; TargetAuroraPostgreSQLEndpoint \u0026gt; | | Port | 5432 | | SSL Mode | none | | User Name | dbmaster | | Password | dbmaster123 | | Database Name | AuroraDB | | Test endpoint connection -\u0026gt; VPC | \u0026lt; VPC ID from Environment Setup Step \u0026gt; | | Replication Instance | oracle-replication |  Once the information has been entered, click Run Test. When the status turns to successful, click Create endpoint.  "
},
{
	"uri": "/2-oracle-aurora/2-migration/6-migration-task/",
	"title": "DMS Migration Task",
	"tags": [],
	"description": "",
	"content": "Contents\n Create a DMS Migration Task   Create a DMS Migration Task AWS DMS uses Database Migration Task to migrate the data from the source to the target database. For this migration, you are going to create two Database Migration Tasks: one for migrating the existing data, and another for capturing data changes on the source database and replicating the changes to the target database.\n Click on Database migration tasks on the left-hand menu, then click on the Create task button on the top right corner.  Create a data migration task with the following values for migrating the dms_sample database.     Parameter Value     Task identifier oracle-migration-task   Replication instance dmsreplication   Source database endpoint oracle-source   Target database endpoint aurora-target   Migration type Migrate existing data   Target table preparation mode Do nothing   Include LOB columns in replication Limited LOB mode   Max LOB size (KB) 32   Enable validation Unchecked   Enable CloudWatch logs Checked    Expand the Table mappings section, and select Wizard for the editing mode. Click on Add new selection rule button and enter the following values in the form:     Parameter Value     Schema DMS_SAMPLE   Table name %   Action Include    If the Create Task screen does not recognize any schemas, make sure to go back to the endpoints screen and click on your endpoint. Scroll to the bottom of the page and click on Refresh Button (⟳) in the Schemas section. If your schemas still do not show up on the Create Task screen, click on the Guided tab and manually select DMS_SAMPLE schema and all tables.\n\rNext, expand the Transformation rules section, and click on Add new transformation rule using the following values:   Rule 1: | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Target | Schema | | Schema Name | DMS_SAMPLE | | Action | Make lowercase |\n  Rule 2: | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Target | Table | | Schema Name | DMS_SAMPLE | | Table Name | % | | Action | Make lowercase |\n  Rule 3: | Parameter | Value | |:\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;:| | Target | Column | | Schema Name | DMS_SAMPLE | | Table Name | % | | Column Name | % | | Action | Make lowercase |\n    After entering the values, make sure Migration task startup configuration is set to start Automatically on create, then click on Create task. At this point, the task should start running and replicating data from the DMS_SAMPLE Oracle database to the Amazon Aurora RDS (PostgreSQL) instance.  As the rows are being transferred, you can monitor the task progress:  Click on your task (oracle-migration-task) and scroll to the Table statistics section to view the table statistics to see how many rows have been moved. If there is an error, the status color changes from green to red. Click on View logs link for the logs to debug.    "
},
{
	"uri": "/2-oracle-aurora/2-migration/7-inspect-content/",
	"title": "Inspect Target Database",
	"tags": [],
	"description": "",
	"content": "Contents\n Inspect the Content of Target Database   Inspect the Content of Target Database If you disconnected from the EC2 instance, follow the instruction in Connect to the EC2 Instance section from the previous part to RDP to the instance.\n\r Open pgAdmin4 from within the EC2 server, and then connect to the Target Aurora RDS (PostgreSQL) database connection that you created earlier. Inspect the migrated data, by querying one of the tables in the target database. For example, the following query should return a table with two rows:  SELECT *\rFROM dms_sample.sport_type;\rBaseball, and football are the only two sports that are currently listed in this table. In the next section you will insert several new records to the source database with information about other sport types. DMS will automatically replicate these new records from the source database to the target database.\n\rNow, use the following script to enable the foreign key constraints that we dropped earlier:  \r\rAdd Constrant File\r\r\rAddConstraintsPostgreSQL.sql\r\r(2 ko)\r\r\r\r Open AddConstraintsPostgreSQL.sql in your favorite text editor. Copy the content of the file to the Query Editor in pgAdmin 4. Execute the script.  "
},
{
	"uri": "/2-oracle-aurora/2-migration/8-replicate-changes/",
	"title": "Replicate Data Changes",
	"tags": [],
	"description": "",
	"content": "Contents\n Replicate Data Changes   Replicate Data Changes Now you are going to simulate a transaction to the source database by updating the sport_type table. The Database Migration Service will automatically detect and replicate these changes to the target database.\n Create another Data Migration Task with the following values for capturing data changes to the source Oracle database, and replicating the changes to the target Aurora RDS instance.     Parameter Value     Task identifier oracle-replication-task   Replication instance oracle-replication   Source database endpoint oracle-source   Target database endpoint aurora-target   Migration type Replicate data changes only   CDC stop mode Don’t use custom CDC stop mode   Target table preparation mode Do nothing   Stop task after full load completes Don’t stop   Include LOB columns in replication Limited LOB mode   Max LOB size (KB) 32   Enable validation Unchecked   Enable CloudWatch logs Checked    Expand the Table mappings section, and select Wizard for the editing mode. Add the same Selection, and Transformation rules as specified in Steps 4,5 - DMS Migration Task.  After entering the values, make sure Migration task startup configuration is set to start Automatically on create, then click on Create task. At this point, the new migration task is ready to replicate ongoing data changes from the source Oracle RDS to the Amazon Aurora RDS (PostgreSQL) database.  Now you are going to simulate a transaction to the source database by updating the sport_type table. The Database Migration Service will automatically detect and replicate these changes to the target database.\nUse Oracle SQL Developer connect to the source Oracle RDS. Open a New Query window and execute the following statement to insert 5 new sports into the sport_type table:  INSERT ALL\rINTO dms_sample.sport_type (name,description) VALUES (\u0026#39;hockey\u0026#39;, \u0026#39;A sport in which two teams play against each other by trying to more a puck into the opponents goal using a hockey stick\u0026#39;)\rINTO dms_sample.sport_type (name,description) VALUES (\u0026#39;basketball\u0026#39;, \u0026#39;A sport in which two teams of five players each that oppose one another shoot a basketball through the defenders hoop\u0026#39;)\rINTO dms_sample.sport_type (name,description) VALUES (\u0026#39;soccer\u0026#39;,\u0026#39;A sport played with a spherical ball between two teams of eleven players\u0026#39;)\rINTO dms_sample.sport_type (name,description) VALUES (\u0026#39;volleyball\u0026#39;,\u0026#39;two teams of six players are separated by a net and each team tries to score by grounding a ball on the others court\u0026#39;)\rINTO dms_sample.sport_type (name,description) VALUES (\u0026#39;cricket\u0026#39;,\u0026#39;A bat-and-ball game between two teams of eleven players on a field with a wicket at each end\u0026#39;)\rSELECT * FROM dual; COMMIT;\rSELECT * FROM dms_sample.sport_type; Repeat steps 1,2 - Inspect Target Database as described earlier to inspect the content of sport_type table in the target database.  The new records for that you added for basketball, cricket, hockey, soccer, volleyball to the sports_type table in the source database have been replicated to your dms_sample database. You can further investigate the number of inserts, deletes, updates, and DDLs by viewing the Table statistics of your Database migration tasks in AWS console.\n\rThe AWS DMS task keeps the target Aurora PostgreSQL database up to date with source database changes. AWS DMS keeps all the tables in the task up to date until it’s time to implement the application migration. The latency is close to zero, when the target has caught up to the source.\n\r"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]